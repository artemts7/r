{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Sber_test (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ztatNQwZsbt"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import tarfile\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.datasets.utils import download_url\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm, trange\n",
        "import imageio\n",
        "from pathlib import Path\n",
        "import skimage\n",
        "from skimage import io\n",
        "from IPython.display import clear_output\n",
        "# import efficientnet_pytorch\n",
        "# from efficientnet_pytorch import EfficientNet"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBS0NvSIdGKB"
      },
      "source": [
        "# 4/1AY0e-g6BwSDQqELiUtGjpEbkmxY0SEpEqOA-rd7DzaKnarZKe2r2Gehg2gE"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_JzVTQeaeE3",
        "outputId": "7f344c98-d97f-4601-9926-2aca6f241244"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8MN3RFYblzY"
      },
      "source": [
        "# План работы\n",
        "1) Предобработка данных(поизучать данные, посмотреть распределение классов, сделать более удобные метки)\n",
        "\n",
        "2) Создание датасета(добавление аугментации, нормализации, изменение размеров для моделей)\n",
        "\n",
        "3)Построение моделей(построить несколько моделей классификации, обучить, выбрать лучшую)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nABwdoynUoLf"
      },
      "source": [
        "#1. Предобработка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aym4J7zcx4O9"
      },
      "source": [
        "Посмотрим, что представляет собой датасет"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "Qlkw3EfKZsbu",
        "outputId": "f5202b2a-4c6f-4423-e575-d312d14f354d"
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/sber/imagewoof2/noisy_imagewoof.csv', sep = ',')\n",
        "df"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>noisy_labels_0</th>\n",
              "      <th>noisy_labels_1</th>\n",
              "      <th>noisy_labels_5</th>\n",
              "      <th>noisy_labels_25</th>\n",
              "      <th>noisy_labels_50</th>\n",
              "      <th>is_valid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train/n02115641/n02115641_3995.JPEG</td>\n",
              "      <td>n02115641</td>\n",
              "      <td>n02115641</td>\n",
              "      <td>n02115641</td>\n",
              "      <td>n02115641</td>\n",
              "      <td>n02115641</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train/n02115641/n02115641_843.JPEG</td>\n",
              "      <td>n02115641</td>\n",
              "      <td>n02115641</td>\n",
              "      <td>n02105641</td>\n",
              "      <td>n02115641</td>\n",
              "      <td>n02088364</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train/n02115641/n02115641_2953.JPEG</td>\n",
              "      <td>n02115641</td>\n",
              "      <td>n02115641</td>\n",
              "      <td>n02115641</td>\n",
              "      <td>n02111889</td>\n",
              "      <td>n02099601</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train/n02115641/n02115641_6458.JPEG</td>\n",
              "      <td>n02115641</td>\n",
              "      <td>n02115641</td>\n",
              "      <td>n02115641</td>\n",
              "      <td>n02093754</td>\n",
              "      <td>n02115641</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train/n02115641/n02115641_19414.JPEG</td>\n",
              "      <td>n02115641</td>\n",
              "      <td>n02115641</td>\n",
              "      <td>n02115641</td>\n",
              "      <td>n02115641</td>\n",
              "      <td>n02088364</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12949</th>\n",
              "      <td>val/n02089973/n02089973_9351.JPEG</td>\n",
              "      <td>n02089973</td>\n",
              "      <td>n02089973</td>\n",
              "      <td>n02089973</td>\n",
              "      <td>n02089973</td>\n",
              "      <td>n02089973</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12950</th>\n",
              "      <td>val/n02089973/n02089973_1241.JPEG</td>\n",
              "      <td>n02089973</td>\n",
              "      <td>n02089973</td>\n",
              "      <td>n02089973</td>\n",
              "      <td>n02089973</td>\n",
              "      <td>n02089973</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12951</th>\n",
              "      <td>val/n02089973/n02089973_4702.JPEG</td>\n",
              "      <td>n02089973</td>\n",
              "      <td>n02089973</td>\n",
              "      <td>n02089973</td>\n",
              "      <td>n02089973</td>\n",
              "      <td>n02089973</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12952</th>\n",
              "      <td>val/n02089973/n02089973_1040.JPEG</td>\n",
              "      <td>n02089973</td>\n",
              "      <td>n02089973</td>\n",
              "      <td>n02089973</td>\n",
              "      <td>n02089973</td>\n",
              "      <td>n02089973</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12953</th>\n",
              "      <td>val/n02089973/n02089973_9591.JPEG</td>\n",
              "      <td>n02089973</td>\n",
              "      <td>n02089973</td>\n",
              "      <td>n02089973</td>\n",
              "      <td>n02089973</td>\n",
              "      <td>n02089973</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12954 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       path  ... is_valid\n",
              "0       train/n02115641/n02115641_3995.JPEG  ...    False\n",
              "1        train/n02115641/n02115641_843.JPEG  ...    False\n",
              "2       train/n02115641/n02115641_2953.JPEG  ...    False\n",
              "3       train/n02115641/n02115641_6458.JPEG  ...    False\n",
              "4      train/n02115641/n02115641_19414.JPEG  ...    False\n",
              "...                                     ...  ...      ...\n",
              "12949     val/n02089973/n02089973_9351.JPEG  ...     True\n",
              "12950     val/n02089973/n02089973_1241.JPEG  ...     True\n",
              "12951     val/n02089973/n02089973_4702.JPEG  ...     True\n",
              "12952     val/n02089973/n02089973_1040.JPEG  ...     True\n",
              "12953     val/n02089973/n02089973_9591.JPEG  ...     True\n",
              "\n",
              "[12954 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvbSo63mZsbv"
      },
      "source": [
        "df['path'] = '/content/drive/My Drive/sber/imagewoof2/' + df['path']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PbGvcPGyD0T"
      },
      "source": [
        "Мы видим, что таргеты имеют тип str, найдём все уникальные значения и перезапишем их числами от [0..n]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "l2EebTmeZsbw",
        "outputId": "b8fc5a79-9ee5-474f-d93d-2bca0afd7214"
      },
      "source": [
        "df.noisy_labels_0.unique()\n",
        "idx1 = {} #словарь для замены имени таргета\n",
        "for i in range(len(df.noisy_labels_0.unique())):\n",
        "    idx1[df.noisy_labels_0.unique()[i]] = i\n",
        "idx2 = {v: k for k, v in idx1.items()}\n",
        "#заменяем\n",
        "df['noisy_labels_0'].replace(idx1, inplace=True)\n",
        "df['noisy_labels_1'].replace(idx1, inplace=True)\n",
        "df['noisy_labels_5'].replace(idx1, inplace=True)\n",
        "df['noisy_labels_25'].replace(idx1, inplace=True)\n",
        "df['noisy_labels_50'].replace(idx1, inplace=True)\n",
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>noisy_labels_0</th>\n",
              "      <th>noisy_labels_1</th>\n",
              "      <th>noisy_labels_5</th>\n",
              "      <th>noisy_labels_25</th>\n",
              "      <th>noisy_labels_50</th>\n",
              "      <th>is_valid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/My Drive/sber/imagewoof2/train/...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/My Drive/sber/imagewoof2/train/...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/My Drive/sber/imagewoof2/train/...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/My Drive/sber/imagewoof2/train/...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/My Drive/sber/imagewoof2/train/...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                path  ...  is_valid\n",
              "0  /content/drive/My Drive/sber/imagewoof2/train/...  ...     False\n",
              "1  /content/drive/My Drive/sber/imagewoof2/train/...  ...     False\n",
              "2  /content/drive/My Drive/sber/imagewoof2/train/...  ...     False\n",
              "3  /content/drive/My Drive/sber/imagewoof2/train/...  ...     False\n",
              "4  /content/drive/My Drive/sber/imagewoof2/train/...  ...     False\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-6FGEYfihaC"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j064xHxkgLdr"
      },
      "source": [
        "## Добавим в df столбец \"test\", отвечающий за train = 0, validation = 1, test =2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTahBTJHWNrs",
        "outputId": "f72a85d5-6a0e-4e59-a9c0-c86e63d05b2d"
      },
      "source": [
        "df['test'] = [0] * 12954\n",
        "df.test[df.is_valid == True] = 1\n",
        "for i in df.index[df.is_valid == True][::4]:\n",
        "  df.test[i] = 2\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlYfFSExWbIQ"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "vKQ-BchuWjEY",
        "outputId": "84742d45-3beb-49d8-c402-9a43e3a1e9bb"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>noisy_labels_0</th>\n",
              "      <th>noisy_labels_1</th>\n",
              "      <th>noisy_labels_5</th>\n",
              "      <th>noisy_labels_25</th>\n",
              "      <th>noisy_labels_50</th>\n",
              "      <th>is_valid</th>\n",
              "      <th>test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/My Drive/sber/imagewoof2/train/...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/My Drive/sber/imagewoof2/train/...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/My Drive/sber/imagewoof2/train/...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/My Drive/sber/imagewoof2/train/...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/My Drive/sber/imagewoof2/train/...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                path  ...  test\n",
              "0  /content/drive/My Drive/sber/imagewoof2/train/...  ...     0\n",
              "1  /content/drive/My Drive/sber/imagewoof2/train/...  ...     0\n",
              "2  /content/drive/My Drive/sber/imagewoof2/train/...  ...     0\n",
              "3  /content/drive/My Drive/sber/imagewoof2/train/...  ...     0\n",
              "4  /content/drive/My Drive/sber/imagewoof2/train/...  ...     0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMTi2UWFyxKD",
        "outputId": "e0350955-700e-47a6-bfdb-755f27ebdc33"
      },
      "source": [
        "(('train', df[df.test== 0].shape[0] / df.shape[0]), ('val',df[df.test== 1].shape[0] / df.shape[0]), ('test', df[df.test == 2].shape[0] / df.shape[0]))#смотрим долю объектов\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('train', 0.6966960012351398),\n",
              " ('val', 0.22742010189902734),\n",
              " ('test', 0.07588389686583295))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2qlF6Qfz9K4"
      },
      "source": [
        "Рассмотрим насколько сбалансированы классы "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "0VedvAS-z-ca",
        "outputId": "5de01e62-8867-45c0-b62d-42699b0dfc93"
      },
      "source": [
        "sns.countplot(x = df.noisy_labels_0, data=df)\n",
        "plt.xlabel('target')\n",
        "plt.title('all dataset')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "99Eha_EUZsbw",
        "outputId": "e7a8e281-5158-466c-d2ef-f352ba84bc85"
      },
      "source": [
        "sns.countplot(x = df.noisy_labels_0[df.test == 0], data=df[df.test == 0])\n",
        "plt.xlabel('target')\n",
        "plt.title('train dataset')\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "eBbKiuOCZsbx",
        "outputId": "1d6629f3-504d-4a3c-b84c-a5284581f662"
      },
      "source": [
        "sns.countplot(x = df.noisy_labels_0[df.test == 1], data=df[df.test == 1])\n",
        "plt.xlabel('target')\n",
        "plt.title('validation dataset')\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXUQjIM_Zsbx",
        "outputId": "656aea71-0551-4f67-845b-40bd19b1d56e"
      },
      "source": [
        "train_data = []\n",
        "test_data = []\n",
        "def process_train(df):\n",
        "    data = []\n",
        "    for image, i in zip(tqdm(df.path, desc = 'Train'), df.index):\n",
        "        item = {}\n",
        "        # img = io.imread(image) # считываем каждую картинку\n",
        "        img = Image.open(image) # считываем каждую картинку\n",
        "        img = transforms.functional.pil_to_tensor(img) \n",
        "        if img.shape[0]>3:\n",
        "            assert(img[:,:,3]!=255).sum()==0 \n",
        "        if img.shape[0]==1:\n",
        "          continue \n",
        "        item['img'] = img #добавляем картинку\n",
        "        item['target'] = df.noisy_labels_0[i] #добавляем таргет\n",
        "        data.append(item)\n",
        "    return data\n",
        "\n",
        "def process_test(df):\n",
        "    data = []\n",
        "    for image, i in zip(tqdm(df.path, desc = 'test|val'), df.index):\n",
        "        item = {}\n",
        "        # img = io.imread(image) # считываем каждую картинку\n",
        "        img = Image.open(image)# считываем каждую картинку\n",
        "        img = transforms.functional.pil_to_tensor(img)\n",
        "        if img.shape[0]>3:\n",
        "            assert(img[:,:,3]!=255).sum()==0 \n",
        "        if img.shape[0]==1:\n",
        "          continue\n",
        "        item['img'] = img #добавляем картинку\n",
        "        item['target'] = df.noisy_labels_0[i] #добавляем таргет\n",
        "        data.append(item)\n",
        "    return data\n",
        "# train_data = process_train(df[df.test == 0])\n",
        "# # valid_data = process_test(df[df.test == 1])\n",
        "# test_data = process_test(df[df.test == 2])\n",
        "train_data = process_train(df[df.is_valid == False])\n",
        "valid_data = process_test(df[df.is_valid == True])\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rTrain:   0%|          | 0/9025 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:169: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
            "  img = torch.as_tensor(np.asarray(pic))\n",
            "Train: 100%|██████████| 9025/9025 [00:56<00:00, 158.92it/s]\n",
            "test|val: 100%|██████████| 3929/3929 [00:24<00:00, 161.16it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zf1z8B0lPO4n",
        "outputId": "f1130fcc-8e72-40d0-d0ee-9abf84ba6479"
      },
      "source": [
        "(len(train_data),len(valid_data))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8943, 3890)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KqkfzIHDSwC"
      },
      "source": [
        "# Так как в train у нас в два раза меньше класса \"9\", чем остальных, мы можем сделать аугментацию, к примеру повернуть картинки класса \"9\", на случайный угол, ответ классификатора, естественно поменяться не должен"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApwpEk5RJFXX"
      },
      "source": [
        "\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Lsp08ygDMJa"
      },
      "source": [
        "# import random\n",
        "# def augmentation(df):\n",
        "#   data_aug = []\n",
        "#   for image, i in zip(tqdm(df.path[:10], desc = 'test|val'), df.index[::10]):\n",
        "#     item = {}\n",
        "#     img = Image.open(image)\n",
        "#     img = transforms.functional.pil_to_tensor(img)\n",
        "#     for j in range(1):\n",
        "#       ang = int(random.random() * 360)\n",
        "#       image = transforms.functional.affine(img, angle = ang, translate = (0,0), scale = 1 , shear = 0) #поворачиваем на случайный угол\n",
        "#     item['img'] = image #добавляем картинки\n",
        "#     item['target'] = df.noisy_labels_0[i] #добавляем таргет\n",
        "#     data_aug.append(item)\n",
        "#   return data_aug\n",
        "\n",
        "# data_aug_train = augmentation(df[(df.test == 0) & (df.noisy_labels_0 ==9)])\n",
        "# data_aug_valid = augmentation(df[(df.test == 1) & (df.noisy_labels_0 ==9)])\n",
        "\n",
        "# train_data = np.concatenate([train_data, data_aug_train])\n",
        "# valid_data = np.concatenate([valid_data, data_aug_valid])\n",
        "\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsYHVGxyKPlk"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SVk26fPNhr8"
      },
      "source": [
        "# len(train_data)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KWFaUDjMq0B"
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WqQZw-453Oq"
      },
      "source": [
        "# image,label  = train_data[500].values()\n",
        "# image = image.reshape(image.shape[1], image.shape[2], image.shape[0])\n",
        "# for i in range(len(valid_data)):\n",
        "#   image,label  = valid_data[i].values()\n",
        "#   if image.shape[0] ==3:\n",
        "#     print(image.shape)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCqEDew_mqDl"
      },
      "source": [
        "# 2) Создаём Dataset (изменяем размеры, аугмуентация, нормализация)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXPGDKzzZsby"
      },
      "source": [
        "###схема трансформации картинки###\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((150,150)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = [0.5,0.5,0.5],std = [0.5,0.5,0.5])\n",
        "    \n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((150,150)), \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = [0.5,0.5,0.5],std = [0.5,0.5,0.5])\n",
        "])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYLBuxx9Zsbz"
      },
      "source": [
        "class Dataset(): #создаём датасет\n",
        "    def __init__(self, data, source_transform):  #задаём, как мы хотим трансформировать призник и таргет\n",
        "        self.datas = data\n",
        "        self.s_transform = source_transform\n",
        "        self.pil_transform = transforms.Compose([transforms.ToPILImage(),\n",
        "                                                 transforms.Resize((128,128))])\n",
        "        self.normalize_tr = transforms.Compose([transforms.ToTensor(),\n",
        "                                                transforms.Normalize(mean = [0.5,0.5,0.5],std = [0.5,0.5,0.5])])\n",
        "    \n",
        "    def __getitem__(self, index): \n",
        "        data = self.datas[index] # берем элемент data\n",
        "        img = data['img'] # достаем картинку \n",
        "        target = data['target']\n",
        "        img = self.s_transform(img) #применяем трансформ к картинке\n",
        "        return img,target\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.datas)\n",
        "    \n",
        "    \n",
        "\n",
        "class TestDataset(): #создаём датасет\n",
        "    def __init__(self, data, source_transform):  #задаём, как мы хотим трансформировать призник и таргет\n",
        "        self.datas = data\n",
        "        self.s_transform = source_transform\n",
        "        self.pil_transform = transforms.Compose([transforms.ToPILImage(),\n",
        "                                                 transforms.Resize((128,128))])\n",
        "        self.normalize_tr = transforms.Compose([transforms.ToTensor(),\n",
        "                                                transforms.Normalize(mean = [0.5,0.5,0.5],std = [0.5,0.5,0.5])])\n",
        "    \n",
        "    def __getitem__(self, index): \n",
        "        data = self.datas[index] # берем элемент data\n",
        "        img = data['img'] # достаем картинку \n",
        "        target = data['target']\n",
        "        img = self.s_transform(img) #применяем трансформ к картинке\n",
        "        return img, target\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.datas)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7ouhIlvZsbz"
      },
      "source": [
        "train_dataset = Dataset(train_data, transform_train)\n",
        "valid_dataset = TestDataset(valid_data, transform_test)\n",
        "test_dataset = TestDataset(test_data, transform_test)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EMw4bdh11FT",
        "outputId": "186ef616-4d22-4628-d46b-977529e2e274"
      },
      "source": [
        "image,label  = valid_dataset[0]\n",
        "print(image.shape, label)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 150, 150]) 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVfkQEVcZsb0"
      },
      "source": [
        "batch_size=128\n",
        "train_dl = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
        "valid_dl = DataLoader(valid_dataset, batch_size, num_workers=0, pin_memory=True)\n",
        "# pred_dl = DataLoader(pred_ds, batch_size, num_workers=4, pin_memory=True)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kayG2w2ro8yl"
      },
      "source": [
        "#3) Построение и обучение моделей"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuaLzqYr1Vxt"
      },
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVv6DR4pZsb0"
      },
      "source": [
        "from torchvision import models"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8hr9AzmZsb0"
      },
      "source": [
        "# modelvgg = models.vgg19(pretrained = True)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsNjIWMIZsb1"
      },
      "source": [
        "# modelvgg"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeYTF3wPZsb1"
      },
      "source": [
        "modelresnet = models.resnet.wide_resnet101_2(pretrained = True)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkTaO4xpz9va"
      },
      "source": [
        "# modeldensenet = models.densenet121(pretrained = True)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1YC9IeWZsb2"
      },
      "source": [
        "# modeldensenet"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWe3-yQm5p48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "428c1bc9-e2bf-4d1e-8b3c-d40815ef91bd"
      },
      "source": [
        "modelresnet"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (6): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (7): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (8): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (9): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (10): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (11): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (12): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (13): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (14): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (15): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (16): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (17): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (18): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (19): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (20): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (21): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (22): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0pOgxPN53kY"
      },
      "source": [
        ""
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrVZlNIa6JRH"
      },
      "source": [
        "for p in modelresnet.parameters() :\n",
        "    p.requires_grad = True"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjmOmdh3Zsb2"
      },
      "source": [
        "# for p in modelvgg.parameters() :\n",
        "#     p.requires_grad = True"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GcZz5xgZsb2"
      },
      "source": [
        "# for p in modeldensenet.parameters() :\n",
        "#     p.requires_grad = True"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIr_ZiVpZsb2"
      },
      "source": [
        "# #изменяем классификатор vgg под нашу задачу \n",
        "# modelvgg.Linear= nn.Sequential(nn.Linear(4096, 2048, bias = True), \n",
        "#                                     nn.ReLU(),\n",
        "#                                     nn.Linear(2048, 1024, bias = True), \n",
        "#                                     nn.ReLU(),\n",
        "#                                     nn.Dropout(p = 0.6),\n",
        "#                                     nn.Linear(1024, 512, bias = True),\n",
        "#                                     nn.ReLU(),\n",
        "#                                     nn.Linear(512, 10, bias = True),\n",
        "#                                     nn.LogSoftmax(dim = 1))"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bto5Q7O8Zsb3"
      },
      "source": [
        ""
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0p8wwTYTZsb3"
      },
      "source": [
        "#изменяем классификатор resnet под нашу задачу\n",
        "modelresnet.fc = nn.Sequential(nn.Linear(2048, 1024, bias = True), \n",
        "                                    nn.ReLU(),\n",
        "                                    nn.Dropout(p = 0.6),\n",
        "                                    nn.Linear(1024, 512, bias = True),\n",
        "                                    nn.ReLU(),\n",
        "                                    nn.Linear(512, 10, bias = True),\n",
        "                                    nn.LogSoftmax(dim = 1))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL-uPWX_6q0W"
      },
      "source": [
        "# # изменяем классификатор efficient под нашу задачу\n",
        "# modeldensenet.classifier = nn.Sequential(nn.Linear(1024, 512, bias=True),\n",
        "#                                     nn.ReLU(),\n",
        "#                                     nn.Linear(512, 128, bias = True), \n",
        "#                                     nn.ReLU(),\n",
        "#                                     nn.Dropout(p = 0.6),\n",
        "#                                     nn.Linear(128, 10, bias = True),\n",
        "#                                     nn.LogSoftmax(dim = 1))"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdDZJNweSeDO"
      },
      "source": [
        "loss_function = F.cross_entropy\n",
        "# loss_function = nn.BCELoss()"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS0mSca_Zsb3"
      },
      "source": [
        "class ImageClassificationBase(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                  # выдём предсказания\n",
        "        loss = loss_function(out, labels) # считаем loss\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                    # выдём предсказания\n",
        "        loss = loss_function(out, labels)   # считаем loss\n",
        "        acc = accuracy(out, labels)           # считаем accuracy\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # считаем средний loss за эпохе\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # считаем accuracy за эпоху\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwEx7EJPZsb3"
      },
      "source": [
        "class IntelCnnModelvgg(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = modelvgg\n",
        "    \n",
        "    def forward(self, xb):\n",
        "        return self.network(xb)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKsIzjBTZsb4"
      },
      "source": [
        "class IntelCnnModelresnet(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = modelresnet\n",
        "    \n",
        "    def forward(self, xb):\n",
        "        return self.network(xb)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpHQpu287i5j"
      },
      "source": [
        "class IntelCnnModeldensenet(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = modeldensenet\n",
        "    \n",
        "    def forward(self, xb):\n",
        "        return self.network(xb)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC5dBtrzZsb4"
      },
      "source": [
        "# model1 = IntelCnnModelvgg()\n",
        "model2 = IntelCnnModelresnet()\n",
        "# model3 = IntelCnnModeldensenet()"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hN04MWMd3yP"
      },
      "source": [
        "#проверка устройства(что работает в данный момент)\n",
        "def get_default_device():\n",
        "  if torch.cuda.is_available:\n",
        "    return torch.device('cuda')\n",
        "  else:\n",
        "    return torch.device('cpu')"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dp5692KdeXrQ",
        "outputId": "1642bcbd-31bc-4d30-efc9-88397c70aa8e"
      },
      "source": [
        "device = get_default_device()\n",
        "device"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pExXGcr7eiWu"
      },
      "source": [
        "#перемещение тензоров на конкретное утройство\n",
        "def to_device(data, device):\n",
        "  if isinstance(data, (list, tuple)):\n",
        "    return [to_device(x, device) for x in data]\n",
        "  return data.to(device, non_blocking = True)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0U5d9L8hdmY"
      },
      "source": [
        "#перемещение данных на конкретное устройство\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZtlSw9DhkOH"
      },
      "source": [
        "# #переводим данные\n",
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "valid_dl = DeviceDataLoader(valid_dl, device)\n",
        "# # pred_dl = DeviceDataLoader(pred_dl, device)\n",
        "# to_device(model1, device);"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ3bUhC7xuFr"
      },
      "source": [
        "#графики loss\n",
        "def plot_losses(history):\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(train_losses, '-bx')\n",
        "    plt.plot(val_losses, '-rx')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Loss')"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gw1uRhdiUOM"
      },
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()   #eval() is called to tell model that now it is validation mode and so don't perform stuff like dropout,backpropagation etc..\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.Adam):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        #Тренируем \n",
        "        model.train() #eval() is called to tell model that now it is training mode and so  perform stuff like dropout,backpropagation etc..\n",
        "        train_losses = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        #резльтат\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "        # clear_output(True)\n",
        "        # plot_losses(history)\n",
        "        # plt.show()\n",
        "    return history"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsXOPZwt2WYa"
      },
      "source": [
        "## Модель VGG19"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEgOCSwnid4S"
      },
      "source": [
        "# model1 = to_device(IntelCnnModelvgg(), device)\n",
        "# # model = to_device(model, device)\n",
        "# evaluate(model1, valid_dl)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHmlYbtffQES"
      },
      "source": [
        "# num_epochs = 10\n",
        "# opt_func = torch.optim.Adam\n",
        "# lr = 0.00001\n",
        "# history = fit(num_epochs, lr, model1, train_dl, valid_dl, opt_func)\n",
        "# evaluate(model1, valid_dl)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1S5WPSWCCxP"
      },
      "source": [
        "# evaluate(model1, valid_dl)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j2tk0Hb2b5A"
      },
      "source": [
        "## Модель ResNet\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tw1_ijOJ1xdm",
        "outputId": "4ae4a337-fc7b-4547-b4d7-48b323f6fd87"
      },
      "source": [
        "model2 = to_device(IntelCnnModelresnet(), device)\n",
        "# model = to_device(model, device)\n",
        "evaluate(model2, valid_dl)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'val_acc': 0.11214717477560043, 'val_loss': 2.3005154132843018}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHValKl4199p",
        "outputId": "84211758-573e-4d26-a696-5d90cce56063"
      },
      "source": [
        "num_epochs = 10\n",
        "opt_func = torch.optim.Adam\n",
        "lr = 0.00001\n",
        "history = fit(num_epochs, lr, model2, train_dl, valid_dl, opt_func)\n",
        "evaluate(model2, valid_dl)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], train_loss: 2.2213, val_loss: 1.8987, val_acc: 0.7986\n",
            "Epoch [1], train_loss: 1.7499, val_loss: 1.0211, val_acc: 0.8508\n",
            "Epoch [2], train_loss: 0.9293, val_loss: 0.4948, val_acc: 0.8675\n",
            "Epoch [3], train_loss: 0.4569, val_loss: 0.2972, val_acc: 0.9203\n",
            "Epoch [4], train_loss: 0.2674, val_loss: 0.2443, val_acc: 0.9288\n",
            "Epoch [5], train_loss: 0.1865, val_loss: 0.2261, val_acc: 0.9273\n",
            "Epoch [6], train_loss: 0.1312, val_loss: 0.2242, val_acc: 0.9301\n",
            "Epoch [7], train_loss: 0.1001, val_loss: 0.2276, val_acc: 0.9289\n",
            "Epoch [8], train_loss: 0.0821, val_loss: 0.2284, val_acc: 0.9287\n",
            "Epoch [9], train_loss: 0.0644, val_loss: 0.2294, val_acc: 0.9266\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'val_acc': 0.9266229271888733, 'val_loss': 0.22937016189098358}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92tBtahe0rgI"
      },
      "source": [
        "# evaluate(model2, valid_dl)"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bi46nIoTRDk"
      },
      "source": [
        "Во время обучения протестил несколько моделей, вот лучшие результаты"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "09_82E-EAs3b",
        "outputId": "5383f1aa-ebc5-402f-8227-74bd708b4011"
      },
      "source": [
        "results"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "</style><table id=\"T_9025c05e_a3d1_11eb_87a3_0242ac1c0002\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >model</th>        <th class=\"col_heading level0 col1\" >val_accuracy</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                                <td id=\"T_9025c05e_a3d1_11eb_87a3_0242ac1c0002row0_col0\" class=\"data row0 col0\" >WideResNet-101-2</td>\n",
              "                        <td id=\"T_9025c05e_a3d1_11eb_87a3_0242ac1c0002row0_col1\" class=\"data row0 col1\" >0.930100</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                                <td id=\"T_9025c05e_a3d1_11eb_87a3_0242ac1c0002row1_col0\" class=\"data row1 col0\" >Resnet152</td>\n",
              "                        <td id=\"T_9025c05e_a3d1_11eb_87a3_0242ac1c0002row1_col1\" class=\"data row1 col1\" >0.926500</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                                <td id=\"T_9025c05e_a3d1_11eb_87a3_0242ac1c0002row2_col0\" class=\"data row2 col0\" >Resnet101</td>\n",
              "                        <td id=\"T_9025c05e_a3d1_11eb_87a3_0242ac1c0002row2_col1\" class=\"data row2 col1\" >0.925400</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                                <td id=\"T_9025c05e_a3d1_11eb_87a3_0242ac1c0002row3_col0\" class=\"data row3 col0\" >Densenet121</td>\n",
              "                        <td id=\"T_9025c05e_a3d1_11eb_87a3_0242ac1c0002row3_col1\" class=\"data row3 col1\" >0.904700</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                                <td id=\"T_9025c05e_a3d1_11eb_87a3_0242ac1c0002row4_col0\" class=\"data row4 col0\" >Resnet50</td>\n",
              "                        <td id=\"T_9025c05e_a3d1_11eb_87a3_0242ac1c0002row4_col1\" class=\"data row4 col1\" >0.900200</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                                <td id=\"T_9025c05e_a3d1_11eb_87a3_0242ac1c0002row5_col0\" class=\"data row5 col0\" >Vgg19</td>\n",
              "                        <td id=\"T_9025c05e_a3d1_11eb_87a3_0242ac1c0002row5_col1\" class=\"data row5 col1\" >0.887300</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                                <td id=\"T_9025c05e_a3d1_11eb_87a3_0242ac1c0002row6_col0\" class=\"data row6 col0\" >Densenet169</td>\n",
              "                        <td id=\"T_9025c05e_a3d1_11eb_87a3_0242ac1c0002row6_col1\" class=\"data row6 col1\" >0.886200</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f04d01f38d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANPkXGyB8NOx"
      },
      "source": [
        "## Модель Densenet-121"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEBXbDVj8PKk"
      },
      "source": [
        "# model3 = to_device(IntelCnnModeldensenet(), device)\n",
        "# model3 = to_device(model3, device)\n",
        "# evaluate(model3, valid_dl)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMCEhRaU8ddG"
      },
      "source": [
        "# num_epochs = 100\n",
        "# opt_func = torch.optim.Adam\n",
        "# lr = 0.00001\n",
        "# history = fit(num_epochs, lr, model3, train_dl, valid_dl, opt_func)\n",
        "# evaluate(model3, valid_dl)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioweU3Ir-iWf"
      },
      "source": [
        "# evaluate(model3, valid_dl)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BA23RHzymSY"
      },
      "source": [
        "## 5)Предсказание"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK1rlVlOfovV"
      },
      "source": [
        "#функция предсказания на общем Тесте\n",
        "\n",
        "# def predict_single(input,label, model):\n",
        "#     input = to_device(input,device)\n",
        "#     inputs = input.unsqueeze(0)   # unsqueeze the input i.e. add an additonal dimension\n",
        "#     predictions = model(inputs)\n",
        "#     prediction = predictions[0].detach().cpu()\n",
        "#     print(f\"Предсказала {np.argmax(prediction)}, должна была предсказать {label}\")"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqWBDtS1S2o_"
      },
      "source": [
        "# for i,img in enumerate(test_dataset):\n",
        "#   print(img[0], img[1])\n",
        "#   predict_single(img[0],img[1], model1)\n",
        "#   break"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRzDpQidwjty"
      },
      "source": [
        "results = pd.DataFrame({'model':['Resnet50','Resnet101', 'Resnet152', 'WideResNet-101-2', 'Vgg19', 'Densenet169', 'Densenet121' ],'val_accuracy':[0.9002, 0.9254, 0.9265, 0.9301, 0.8873, 0.8862, 0.9047  ]})"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8p8UlaMwvCq"
      },
      "source": [
        "results = results.sort_values(by ='val_accuracy', ascending=False)\n"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9PtRUU2QHAR"
      },
      "source": [
        "results = results.style.hide_index()"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "5tKnuWv3R_DV",
        "outputId": "131a800e-49af-4a63-bfc1-2f92f9c31ca1"
      },
      "source": [
        "results"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "</style><table id=\"T_7dfe5fbc_a3d1_11eb_87a3_0242ac1c0002\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >model</th>        <th class=\"col_heading level0 col1\" >val_accuracy</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                                <td id=\"T_7dfe5fbc_a3d1_11eb_87a3_0242ac1c0002row0_col0\" class=\"data row0 col0\" >WideResNet-101-2</td>\n",
              "                        <td id=\"T_7dfe5fbc_a3d1_11eb_87a3_0242ac1c0002row0_col1\" class=\"data row0 col1\" >0.930100</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                                <td id=\"T_7dfe5fbc_a3d1_11eb_87a3_0242ac1c0002row1_col0\" class=\"data row1 col0\" >Resnet152</td>\n",
              "                        <td id=\"T_7dfe5fbc_a3d1_11eb_87a3_0242ac1c0002row1_col1\" class=\"data row1 col1\" >0.926500</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                                <td id=\"T_7dfe5fbc_a3d1_11eb_87a3_0242ac1c0002row2_col0\" class=\"data row2 col0\" >Resnet101</td>\n",
              "                        <td id=\"T_7dfe5fbc_a3d1_11eb_87a3_0242ac1c0002row2_col1\" class=\"data row2 col1\" >0.925400</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                                <td id=\"T_7dfe5fbc_a3d1_11eb_87a3_0242ac1c0002row3_col0\" class=\"data row3 col0\" >Densenet121</td>\n",
              "                        <td id=\"T_7dfe5fbc_a3d1_11eb_87a3_0242ac1c0002row3_col1\" class=\"data row3 col1\" >0.904700</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                                <td id=\"T_7dfe5fbc_a3d1_11eb_87a3_0242ac1c0002row4_col0\" class=\"data row4 col0\" >Resnet50</td>\n",
              "                        <td id=\"T_7dfe5fbc_a3d1_11eb_87a3_0242ac1c0002row4_col1\" class=\"data row4 col1\" >0.900200</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                                <td id=\"T_7dfe5fbc_a3d1_11eb_87a3_0242ac1c0002row5_col0\" class=\"data row5 col0\" >Vgg19</td>\n",
              "                        <td id=\"T_7dfe5fbc_a3d1_11eb_87a3_0242ac1c0002row5_col1\" class=\"data row5 col1\" >0.887300</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                                <td id=\"T_7dfe5fbc_a3d1_11eb_87a3_0242ac1c0002row6_col0\" class=\"data row6 col0\" >Densenet169</td>\n",
              "                        <td id=\"T_7dfe5fbc_a3d1_11eb_87a3_0242ac1c0002row6_col1\" class=\"data row6 col1\" >0.886200</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f04d01f38d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLnbG1WFS-Cy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}